{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11614ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Sample document and apply following document preprocessing methods:\n",
    "# Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c1b0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib64/python3.8/site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b54b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/TE/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bce1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"GeeksforGeeks is a great learning platform . It is one of the best for Computer Science students. play playing played communication \"\n",
    "words = (word_tokenize(sent))\n",
    "sentences = (sent_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42f40d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GeeksforGeeks', 'is', 'a', 'great', 'learning', 'platform', '.', 'It', 'is', 'one', 'of', 'the', 'best', 'for', 'Computer', 'Science', 'students', '.', 'play', 'playing', 'played', 'communication']\n",
      "['GeeksforGeeks is a great learning platform .', 'It is one of the best for Computer Science students.', 'play playing played communication']\n"
     ]
    }
   ],
   "source": [
    "print(words)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff906e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6110cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['geeksforgeek', 'is', 'a', 'great', 'learn', 'platform', '.', 'it', 'is', 'one', 'of', 'the', 'best', 'for', 'comput', 'scienc', 'student', '.', 'play', 'play', 'play', 'commun']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stem = []\n",
    "for i in words:\n",
    "    stem_word = ps.stem(i);\n",
    "    stem.append(stem_word);\n",
    "    \n",
    "print(stem)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ad0653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GeeksforGeeks', 'be', 'a', 'great', 'learn', 'platform', '.', 'It', 'be', 'one', 'of', 'the', 'best', 'for', 'Computer', 'Science', 'students', '.', 'play', 'play', 'play', 'communication']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lem = []\n",
    "for i in words:\n",
    "    lem_word = lemmatizer.lemmatize(i,'v');\n",
    "    lem.append(lem_word);\n",
    "    \n",
    "print(lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e8c83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcb5490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "175b251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32da75de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GeeksforGeeks', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('great', 'JJ'), ('learning', 'JJ'), ('platform', 'NN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('for', 'IN'), ('Computer', 'NNP'), ('Science', 'NNP'), ('students', 'NNS'), ('.', '.'), ('play', 'VB'), ('playing', 'VBG'), ('played', 'JJ'), ('communication', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(tags)\n",
    "sw_nltk = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1690b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "sw_nltk = stopwords.words('english')\n",
    "print(sw_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed94dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeeksforGeeks great learning platform . one best Computer Science students . play playing played communication\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wordAbs = [word for word in words if word.lower() not in sw_nltk]\n",
    "new_text = \" \".join(wordAbs)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27a9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create representation of document by calculating Term Frequency and Inverse Document\n",
    "# Frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b86061f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Science', 'is', 'data', 'century', 'job', 'the', 'Data', 'of', '21st', 'sexiest', 'machine', 'key', 'science', 'learning', 'for'}\n"
     ]
    }
   ],
   "source": [
    "first_sentence = \"Data Science is the sexiest job of the 21st century\"\n",
    "second_sentence = \"machine learning is the key for data science\"\n",
    "#split so each word have their own string\n",
    "first_sentence = first_sentence.split(\" \")\n",
    "second_sentence = second_sentence.split(\" \")#join them to remove common duplicate words\n",
    "total= set(first_sentence).union(set(second_sentence))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2f5955",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictA = dict.fromkeys(total, 0) \n",
    "wordDictB = dict.fromkeys(total, 0)\n",
    "for word in first_sentence:\n",
    "    wordDictA[word]+=1\n",
    "    \n",
    "for word in second_sentence:\n",
    "    wordDictB[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbc259d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Science</th>\n",
       "      <th>is</th>\n",
       "      <th>data</th>\n",
       "      <th>century</th>\n",
       "      <th>job</th>\n",
       "      <th>the</th>\n",
       "      <th>Data</th>\n",
       "      <th>of</th>\n",
       "      <th>21st</th>\n",
       "      <th>sexiest</th>\n",
       "      <th>machine</th>\n",
       "      <th>key</th>\n",
       "      <th>science</th>\n",
       "      <th>learning</th>\n",
       "      <th>for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Science  is  data  century  job  the  Data  of  21st  sexiest  machine  \\\n",
       "0        1   1     0        1    1    2     1   1     1        1        0   \n",
       "1        0   1     1        0    0    1     0   0     0        0        1   \n",
       "\n",
       "   key  science  learning  for  \n",
       "0    0        0         0    0  \n",
       "1    1        1         1    1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf218d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(corpusCount)\n",
    "    return(tfDict)\n",
    "#running our sentences through the tf function:\n",
    "tfFirst = computeTF(wordDictA, first_sentence)\n",
    "tfSecond = computeTF(wordDictB, second_sentence)\n",
    "#Converting to dataframe for visualization\n",
    "tf = pd.DataFrame([tfFirst, tfSecond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dffe5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Science</th>\n",
       "      <th>is</th>\n",
       "      <th>data</th>\n",
       "      <th>century</th>\n",
       "      <th>job</th>\n",
       "      <th>the</th>\n",
       "      <th>Data</th>\n",
       "      <th>of</th>\n",
       "      <th>21st</th>\n",
       "      <th>sexiest</th>\n",
       "      <th>machine</th>\n",
       "      <th>key</th>\n",
       "      <th>science</th>\n",
       "      <th>learning</th>\n",
       "      <th>for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Science     is   data  century  job    the  Data   of  21st  sexiest  \\\n",
       "0      0.1  0.100  0.000      0.1  0.1  0.200   0.1  0.1   0.1      0.1   \n",
       "1      0.0  0.125  0.125      0.0  0.0  0.125   0.0  0.0   0.0      0.0   \n",
       "\n",
       "   machine    key  science  learning    for  \n",
       "0    0.000  0.000    0.000     0.000  0.000  \n",
       "1    0.125  0.125    0.125     0.125  0.125  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dfcfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
    "        \n",
    "    return(idfDict)\n",
    "#inputing our sentences in the log file\n",
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9429880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Science': 0.3010299956639812,\n",
       " 'is': 0.3010299956639812,\n",
       " 'data': 0.3010299956639812,\n",
       " 'century': 0.3010299956639812,\n",
       " 'job': 0.3010299956639812,\n",
       " 'the': 0.3010299956639812,\n",
       " 'Data': 0.3010299956639812,\n",
       " 'of': 0.3010299956639812,\n",
       " '21st': 0.3010299956639812,\n",
       " 'sexiest': 0.3010299956639812,\n",
       " 'machine': 0.3010299956639812,\n",
       " 'key': 0.3010299956639812,\n",
       " 'science': 0.3010299956639812,\n",
       " 'learning': 0.3010299956639812,\n",
       " 'for': 0.3010299956639812}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc78d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
